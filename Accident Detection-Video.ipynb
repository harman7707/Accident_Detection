{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c20982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d50c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accidents.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1ec509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x287d8b1aa60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da41986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_ID  Class\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      1\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a7f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8119c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7cf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2555ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21006e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af20a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d94402",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb02ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 13s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((155, 7, 7, 512), (67, 7, 7, 512))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(67, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5a6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57001716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586cff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36420f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e00a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.7007 - accuracy: 0.6516 - val_loss: 0.7226 - val_accuracy: 0.6716\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.2682 - accuracy: 0.9032 - val_loss: 0.8212 - val_accuracy: 0.7164\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.1615 - accuracy: 0.9742 - val_loss: 0.8369 - val_accuracy: 0.6866\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.1076 - accuracy: 0.9742 - val_loss: 0.8186 - val_accuracy: 0.7164\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.0850 - accuracy: 0.9871 - val_loss: 0.8134 - val_accuracy: 0.7910\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.0609 - accuracy: 0.9935 - val_loss: 0.8466 - val_accuracy: 0.7463\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7910\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7910\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.8303 - val_accuracy: 0.7910\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.8474 - val_accuracy: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x287ea3466d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "494768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d52fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accident-1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf0f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9047ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f32558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1260b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 826ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 7, 7, 512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9f69282",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image.reshape(9, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "721c02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb5b165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00240295 0.99759704]\n",
      " [0.03149246 0.9685075 ]\n",
      " [0.06112293 0.93887705]\n",
      " [0.05671637 0.9432836 ]\n",
      " [0.11091973 0.88908035]\n",
      " [0.7578289  0.24217117]\n",
      " [0.8907449  0.10925514]\n",
      " [0.8531298  0.14687021]\n",
      " [0.93721884 0.06278117]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f040ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,9):\n",
    "    if predictions[i][0]<predictions[i][1]:\n",
    "        print(\"No Accident\")\n",
    "    else:\n",
    "        print(\"Accident\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e66b91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "g = geocoder.ip('me')\n",
    "locname = geoLoc.reverse(g.latlng)\n",
    "account_sid = \"AC8d25ed394916e01596edd70b2abd77a1\"\n",
    "auth_token = \"98bd4f96d016af71efbb0f21811d835d\"\n",
    "client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80b3e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Accident-1.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            predict=\"No Accident\"\n",
    "        else:\n",
    "            predict=\"Accident\"\n",
    "            flag=1\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag==1:\n",
    "    client.messages.create(\n",
    "                 body=\"Accident detected in \"+locname.address,\n",
    "                 from_= \"+16502977583\",\n",
    "                 to= \"+919654429598\" )\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcec9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f67e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b6a86691e1abdfc8794860ef988332cb9263e1040a260a527577bcfca3a3e71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
